{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mission 2-1\n",
        "\n",
        "1. 파일 이름에서 정보 추출 함수 (extract_info_from_filename)\n",
        "def extract_info_from_filename(filename, type):\n",
        "    parts = filename.split('_')\n",
        "    info = {\n",
        "        'W_T': parts[0],\n",
        "        'image_id': parts[1],\n",
        "        'era': parts[2],\n",
        "        'style': parts[3],\n",
        "        'gender': parts[4] if type==0 else parts[4].split('.')[0],\n",
        "        **({'survey_id': parts[5].split('.')[0]} if type == 0 else {})\n",
        "    }\n",
        "    return info\n",
        "\n",
        "설명:\n",
        "- 이 함수는 주어진 파일 이름을 split하여 필요한 정보를 딕셔너리 형태로 반환합니다.\n",
        "- 파라미터: type 파라미터는 파일 유형을 나타내며, type=0일 때는 라벨 파일(.json), type=1일 때는 이미지 파일(.jpg)로 처리합니다.\n",
        "- type=0인 경우, survey_id도 포함하여 라벨 파일에서 추가적으로 필요한 정보를 딕셔너리에 저장합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 이 함수는 파일명 형식을 활용해 각 이미지의 image_id, 성별(gender), 스타일(style) 등의 메타 데이터를 추출하여 라벨 데이터와 매칭할 준비를 합니다.\n",
        "\n",
        "2. 폴더 내 파일 처리 함수 (process_folder)\n",
        "def process_folder(folder_path):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.json'):\n",
        "            info = extract_info_from_filename(filename, 0)\n",
        "            info['filename'] = filename\n",
        "            data.append(info)\n",
        "        \n",
        "        elif filename.endswith('.jpg'):\n",
        "            info = extract_info_from_filename(filename, 1)\n",
        "            info['filename'] = filename\n",
        "            data.append(info)\n",
        "            \n",
        "    return data\n",
        "\n",
        "설명:\n",
        "- process_folder 함수는 지정된 폴더의 모든 파일을 순회하며, 파일이 .json 확장자인 경우 라벨 파일로, .jpg 확장자인 경우 이미지 파일로 처리합니다.\n",
        "- extract_info_from_filename 함수를 호출하여 파일명을 통해 필요한 정보를 추출하고, data 리스트에 저장합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 학습 및 검증 데이터 폴더의 라벨 및 이미지 파일을 각각 처리하여 필요한 정보를 추출하고, 이후 데이터 필터링에 사용할 수 있도록 준비합니다.\n",
        "\n",
        "3. 공통 항목으로 라벨 데이터 필터링 (filter_labels_with_images)\n",
        "def filter_labels_with_images(label_df, image_df, common_columns):\n",
        "    return label_df[\n",
        "        label_df[common_columns].apply(tuple, axis=1).isin(\n",
        "            image_df[common_columns].apply(tuple, axis=1))\n",
        "    ]\n",
        "\n",
        "설명:\n",
        "- 이 함수는 이미지 데이터(image_df)에 포함된 항목과 일치하는 라벨 데이터만 필터링하여 반환합니다.\n",
        "- 작동 원리: label_df와 image_df에서 각각 common_columns 열을 이용해 각 행을 튜플 형태로 변환하고, isin()을 사용하여 이미지와 일치하는 라벨만 필터링합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 문제 조건에 따라 유효한 라벨만을 남기기 위해, 이미지와 일치하는 라벨 데이터만 필터링하여 남겨두는 작업을 수행합니다.\n",
        "\n",
        "4. 데이터 처리\n",
        "train_image_data = process_folder('data/training_image')\n",
        "valid_image_data = process_folder('data/validation_image')\n",
        "train_label_data = process_folder('data/training_label')\n",
        "valid_label_data = process_folder('data/validation_label')\n",
        "\n",
        "설명:\n",
        "- 학습과 검증 이미지 및 라벨 데이터의 경로를 지정하고, 각각 process_folder 함수를 호출하여 라벨과 이미지 데이터 정보를 모두 추출합니다.\n",
        "- 결과는 train_image_data, valid_image_data, train_label_data, valid_label_data로 저장됩니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 각 데이터셋을 불러와 필터링 작업을 수행할 준비를 합니다.\n",
        "\n",
        "5. 데이터를 DataFrame으로 변환\n",
        "train_label_df = pd.DataFrame(train_label_data)\n",
        "valid_label_df = pd.DataFrame(valid_label_data)\n",
        "train_image_df = pd.DataFrame(train_image_data)\n",
        "valid_image_df = pd.DataFrame(valid_image_data)\n",
        "\n",
        "설명:\n",
        "- 추출된 데이터(train_label_data, valid_label_data, train_image_data, valid_image_data)를 각각 DataFrame으로 변환합니다.\n",
        "- 이는 이후 데이터 분석 및 필터링을 보다 쉽게 수행할 수 있도록 하기 위함입니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- DataFrame 형식으로 변환하여 필터링 및 통계 처리가 용이하게 만듭니다.\n",
        "\n",
        "6. 필터링 전 데이터 개수 확인\n",
        "print(\"Training 라벨 데이터 개수(필터링 전): \", train_label_df.shape[0])\n",
        "print(\"Validation 라벨 데이터 개수(필터링 전): \", valid_label_df.shape[0])\n",
        "\n",
        "설명:\n",
        "- 필터링을 수행하기 전에 학습 및 검증 라벨 데이터의 개수를 출력하여, 필터링 후의 데이터 개수와 비교할 수 있도록 합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 필터링 전과 후의 데이터 수를 비교하여, 유효한 라벨 데이터만 남았는지 확인할 수 있습니다.\n",
        "\n",
        "7. 공통된 열을 기준으로 데이터셋에서 매칭되는 라벨 필터링\n",
        "common_columns = ['W_T', 'image_id', 'era', 'style', 'gender']\n",
        "filtered_train_label_df = filter_labels_with_images(train_label_df, train_image_df, common_columns)\n",
        "filtered_valid_label_df = filter_labels_with_images(valid_label_df, valid_image_df, common_columns)\n",
        "\n",
        "설명:\n",
        "- common_columns를 기준으로 학습 및 검증 라벨 데이터에서 이미지와 매칭되는 라벨만 필터링합니다.\n",
        "- 필터링 결과는 filtered_train_label_df와 filtered_valid_label_df에 저장됩니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 유효한 라벨 데이터만 남기는 작업으로, 이미지 데이터와 매칭되는 라벨만을 남겨 Mission 2-1의 요구 사항을 만족합니다.\n",
        "\n",
        "8. 필터링 후 데이터 개수 출력\n",
        "print(\"\\nTraining 라벨 데이터 개수(필터링 후): \", filtered_train_label_df.shape[0])\n",
        "print(\"Validation 라벨 데이터 개수(필터링 후): \", filtered_valid_label_df.shape[0])\n",
        "\n",
        "설명:\n",
        "- 필터링 후 데이터의 개수를 출력하여 필터링 전과 비교할 수 있도록 합니다.\n",
        "이를 통해 필터링 작업이 올바르게 수행되었는지 검증할 수 있습니다.\n",
        "\n",
        "9. CSV 파일로 저장\n",
        "# filtered_train_label_df.to_csv('data/filtered_train_label_metadata.csv', index=False)\n",
        "# filtered_valid_label_df.to_csv('data/filtered_valid_label_metadata.csv', index=False)\n",
        "\n",
        "설명:\n",
        "- 필터링된 학습 및 검증 라벨 데이터를 CSV 파일로 저장하여, 이후 분석 및 모델 학습에 사용될 수 있도록 준비합니다.\n",
        "- 이 과정은 주석 처리되어 있지만, 필요 시 주석을 제거해 CSV 파일로 저장할 수 있습니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "최종적으로 유효한 라벨 데이터셋을 별도 파일로 저장함으로써 데이터 준비를 완료하고, 이후의 작업에 사용할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "1. 성별 & 스타일별 개수를 세는 함수 (count_by_gender_and_style)\n",
        "def count_by_gender_and_style(df):\n",
        "    return df.groupby(['gender', 'style']).size().reset_index(name='count')\n",
        "\n",
        "설명:\n",
        "- 이 함수는 주어진 데이터프레임 df에서 gender와 style 열을 기준으로 그룹화하여 각 성별과 스타일 조합의 개수를 세고, 결과를 DataFrame 형태로 반환합니다.\n",
        "- groupby를 통해 성별과 스타일을 그룹화한 후 size()를 사용하여 각 그룹의 개수를 세고, reset_index(name='count')로 각 조합과 개수를 포함한 새로운 데이터프레임을 생성합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 이 함수는 유효한 라벨 데이터를 기반으로 성별과 스타일별로 통계를 집계해야 한다는 Mission 2-1의 요구 사항을 충족합니다.\n",
        "\n",
        "2. 유효한 라벨 데이터에서 성별 & 스타일별 개수 집계\n",
        "train_gender_style_counts = count_by_gender_and_style(filtered_train_label_df)\n",
        "valid_gender_style_counts = count_by_gender_and_style(filtered_valid_label_df)\n",
        "\n",
        "설명:\n",
        "- Mission 2-1에서 필터링된 학습 및 검증 라벨 데이터프레임(filtered_train_label_df, filtered_valid_label_df)을 입력으로 하여 count_by_gender_and_style 함수를 호출합니다.\n",
        "- 학습 데이터(train_gender_style_counts)와 검증 데이터(valid_gender_style_counts)에서 성별 및 스타일 조합별 개수를 각각 집계합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 이 작업을 통해 유효한 학습 및 검증 데이터에서 각 성별과 스타일 조합에 해당하는 이미지 개수를 집계하게 되므로, Mission 2-1의 요구 사항에 부합합니다.\n",
        "\n",
        "\n",
        "3. 결과 출력\n",
        "print(\"Training gender & style counts:\")\n",
        "print(train_gender_style_counts)\n",
        "\n",
        "print(\"\\nValidation gender & style counts:\")\n",
        "print(valid_gender_style_counts)\n",
        "\n",
        "설명:\n",
        "- 학습 및 검증 데이터에 대한 성별 및 스타일별 통계 결과를 출력하여 개별 성별 및 스타일 조합에 속한 이미지 수를 확인할 수 있습니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- 통계 결과를 확인할 수 있도록 출력하여, 데이터의 전반적인 분포를 파악할 수 있게 합니다.\n",
        "\n",
        "4. 결과 제출용 CSV 파일 저장\n",
        "train_gender_style_counts.to_csv('Mission2-1 Training Result.csv', index=False)\n",
        "valid_gender_style_counts.to_csv('Mission2-1 Validation Result.csv', index=False)\n",
        "\n",
        "설명:\n",
        "- to_csv 메서드를 사용해 학습 및 검증 데이터의 성별 & 스타일별 통계 결과를 각각 CSV 파일로 저장합니다.\n",
        "- index=False는 데이터프레임의 인덱스가 CSV 파일에 포함되지 않도록 설정하여, 간결한 형태로 결과를 저장합니다.\n",
        "\n",
        "Mission 2-1 요구 사항:\n",
        "- CSV 파일 형식으로 통계를 저장하여 Mission 2-1의 결과를 제출할 수 있도록 준비합니다. 학습 결과는 Mission2-1 Training Result.csv에, 검증 결과는 Mission2-1 Validation Result.csv에 각각 저장됩니다.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3c08cd0adc72f187"
      },
      "id": "3c08cd0adc72f187"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training 라벨 데이터 개수(필터링 전):  211346\n",
            "Validation 라벨 데이터 개수(필터링 전):  36383\n",
            "\n",
            "Training 라벨 데이터 개수(필터링 후):  16096\n",
            "Validation 라벨 데이터 개수(필터링 후):  4105\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 이름에서 정보 추출 (type = {label= 0, image= 1})\n",
        "def extract_info_from_filename(filename, type):\n",
        "    parts = filename.split('_')\n",
        "    info = {\n",
        "        'W_T': parts[0],\n",
        "        'image_id': parts[1],\n",
        "        'era': parts[2],\n",
        "        'style': parts[3],\n",
        "        'gender': parts[4] if type==0 else parts[4].split('.')[0],\n",
        "        **({'survey_id': parts[5].split('.')[0]} if type == 0 else {})\n",
        "    }\n",
        "    return info\n",
        "\n",
        "# 폴더에 있는 파일 처리\n",
        "def process_folder(folder_path):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.json'):\n",
        "            info = extract_info_from_filename(filename, 0)\n",
        "            info['filename'] = filename\n",
        "            data.append(info)\n",
        "\n",
        "        elif filename.endswith('.jpg'):\n",
        "            info = extract_info_from_filename(filename, 1)\n",
        "            info['filename'] = filename\n",
        "            data.append(info)\n",
        "\n",
        "    return data\n",
        "\n",
        "# 공통된 항목을 비교하여 매칭되는 라벨만 필터링하는 함수\n",
        "def filter_labels_with_images(label_df, image_df, common_columns):\n",
        "    return label_df[\n",
        "        label_df[common_columns].apply(tuple, axis=1).isin(\n",
        "            image_df[common_columns].apply(tuple, axis=1))\n",
        "    ]\n",
        "\n",
        "\n",
        "# 데이터 처리\n",
        "train_image_data = process_folder('data/training_image')\n",
        "valid_image_data = process_folder('data/validation_image')\n",
        "train_label_data = process_folder('data/training_label')\n",
        "valid_label_data = process_folder('data/validation_label')\n",
        "\n",
        "# 데이터를 DataFrame으로 변환\n",
        "train_label_df = pd.DataFrame(train_label_data)\n",
        "valid_label_df = pd.DataFrame(valid_label_data)\n",
        "train_image_df = pd.DataFrame(train_image_data)\n",
        "valid_image_df = pd.DataFrame(valid_image_data)\n",
        "\n",
        "# 필터링 전 데이터 개수\n",
        "print(\"Training 라벨 데이터 개수(필터링 전): \", train_label_df.shape[0])\n",
        "print(\"Validation 라벨 데이터 개수(필터링 전): \", valid_label_df.shape[0])\n",
        "\n",
        "# 공통된 열 정의\n",
        "common_columns = ['W_T', 'image_id', 'era', 'style', 'gender']\n",
        "\n",
        "# 데이터셋에서 매칭되는 라벨만 필터링\n",
        "filtered_train_label_df = filter_labels_with_images(train_label_df, train_image_df, common_columns)\n",
        "filtered_valid_label_df = filter_labels_with_images(valid_label_df, valid_image_df, common_columns)\n",
        "\n",
        "# 필터링된 결과 출력\n",
        "print(\"\\nTraining 라벨 데이터 개수(필터링 후): \", filtered_train_label_df.shape[0])\n",
        "print(\"Validation 라벨 데이터 개수(필터링 후): \", filtered_valid_label_df.shape[0])\n",
        "\n",
        "# CSV 파일로 저장\n",
        "# filtered_train_label_df.to_csv('data/filtered_train_label_metadata.csv', index=False)\n",
        "# filtered_valid_label_df.to_csv('data/filtered_valid_label_metadata.csv', index=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-30T06:30:26.481716Z",
          "start_time": "2024-10-30T06:30:23.420936Z"
        },
        "id": "initial_id",
        "outputId": "6d992645-7daa-4b54-fe80-840fbd8a3c28"
      },
      "id": "initial_id"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training gender & style counts:\n",
            "   gender           style  count\n",
            "0       M            bold   1007\n",
            "1       M          hiphop   1070\n",
            "2       M          hippie   1502\n",
            "3       M             ivy   1608\n",
            "4       M     metrosexual   1045\n",
            "5       M            mods   1458\n",
            "6       M        normcore    644\n",
            "7       M  sportivecasual    845\n",
            "8       W      athleisure    378\n",
            "9       W   bodyconscious    455\n",
            "10      W        cityglam    231\n",
            "11      W         classic    360\n",
            "12      W           disco    130\n",
            "13      W         ecology    223\n",
            "14      W        feminine    719\n",
            "15      W      genderless    146\n",
            "16      W          grunge     90\n",
            "17      W          hiphop    138\n",
            "18      W          hippie    308\n",
            "19      W          kitsch    261\n",
            "20      W        lingerie    156\n",
            "21      W          lounge     82\n",
            "22      W        military    109\n",
            "23      W         minimal    643\n",
            "24      W        normcore    278\n",
            "25      W        oriental    282\n",
            "26      W          popart    193\n",
            "27      W       powersuit    531\n",
            "28      W            punk    218\n",
            "29      W           space    171\n",
            "30      W  sportivecasual    815\n",
            "\n",
            "Validation gender & style counts:\n",
            "   gender           style  count\n",
            "0       M            bold    215\n",
            "1       M          hiphop    256\n",
            "2       M          hippie    474\n",
            "3       M             ivy    537\n",
            "4       M     metrosexual    224\n",
            "5       M            mods    437\n",
            "6       M        normcore     89\n",
            "7       M  sportivecasual    148\n",
            "8       W      athleisure     80\n",
            "9       W   bodyconscious    111\n",
            "10      W        cityglam     61\n",
            "11      W         classic    102\n",
            "12      W           disco     31\n",
            "13      W         ecology     65\n",
            "14      W        feminine    208\n",
            "15      W      genderless     24\n",
            "16      W          grunge     29\n",
            "17      W          hiphop     23\n",
            "18      W          hippie     46\n",
            "19      W          kitsch     61\n",
            "20      W        lingerie     15\n",
            "21      W          lounge     16\n",
            "22      W        military     32\n",
            "23      W         minimal    164\n",
            "24      W        normcore     39\n",
            "25      W        oriental     67\n",
            "26      W          popart     38\n",
            "27      W       powersuit    151\n",
            "28      W            punk     38\n",
            "29      W           space     70\n",
            "30      W  sportivecasual    254\n"
          ]
        }
      ],
      "source": [
        "# Mission 2-1\n",
        "def count_by_gender_and_style(df):\n",
        "    return df.groupby(['gender', 'style']).size().reset_index(name='count')\n",
        "\n",
        "\n",
        "# 데이터셋에서 성별 & 스타일 별 개수 세기\n",
        "train_gender_style_counts = count_by_gender_and_style(filtered_train_label_df)\n",
        "valid_gender_style_counts = count_by_gender_and_style(filtered_valid_label_df)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Training gender & style counts:\")\n",
        "print(train_gender_style_counts)\n",
        "\n",
        "print(\"\\nValidation gender & style counts:\")\n",
        "print(valid_gender_style_counts)\n",
        "\n",
        "# 결과 제출용\n",
        "train_gender_style_counts.to_csv('Mission2-1 Training Result.csv', index=False)\n",
        "valid_gender_style_counts.to_csv('Mission2-1 Validation Result.csv', index=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-30T06:30:31.694683Z",
          "start_time": "2024-10-30T06:30:31.656601Z"
        },
        "id": "de9014754a9b6196",
        "outputId": "0b1ac19f-7974-450f-9353-f4d9eb4d72d6"
      },
      "id": "de9014754a9b6196"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mission 2-2\n",
        "\n",
        "1. 설문 조사에서 필요한 정보만 추출하는 함수 (extract_info_from_survey)\n",
        "\n",
        "import json\n",
        "\n",
        "def extract_info_from_survey(filenames, type):\n",
        "    data = []\n",
        "    dir = \"data/training_label/\" if type==0 else \"data/validation_label/\"\n",
        "    \n",
        "    for filename in filenames:\n",
        "        with open(dir + filename, 'r') as file:\n",
        "            survey_data = json.load(file)\n",
        "            extracted_data = {\n",
        "                'R_id': survey_data['user']['R_id'],\n",
        "                'image_id': survey_data['imgName'],\n",
        "                'Q5': survey_data['item']['survey']['Q5']\n",
        "            }\n",
        "            data.append(extracted_data)\n",
        "            \n",
        "    return data\n",
        "\n",
        "설명:\n",
        "- 설문 조사 데이터에서 필요한 정보(R_id, image_id, Q5)만 추출하여 리스트 data에 저장합니다.\n",
        "- R_id는 응답자 ID, image_id는 이미지 식별자, Q5는 스타일 선호 여부를 나타냅니다.\n",
        "- 파라미터:\n",
        "filenames는 필터링된 라벨 데이터프레임에서 가져온 파일 이름 목록입니다.\n",
        "type은 0(학습 데이터) 또는 1(검증 데이터)으로 구분하여 올바른 디렉토리 경로를 선택합니다.\n",
        "\n",
        "Mission 2-2 요구 사항:\n",
        "- 설문 조사 파일에서 각 응답자의 ID와 이미지별 선호 여부 정보를 추출하여 이후 응답자별로 선호/비선호 스타일 정보를 구성할 수 있도록 준비합니다.\n",
        "\n",
        "2. 데이터 추출 및 DataFrame으로 변환\n",
        "train_survey_data = extract_info_from_survey(filtered_train_label_df['filename'], 0)\n",
        "valid_survey_data = extract_info_from_survey(filtered_valid_label_df['filename'], 1)\n",
        "\n",
        "train_survey_df = pd.DataFrame(train_survey_data)\n",
        "valid_survey_df = pd.DataFrame(valid_survey_data)\n",
        "\n",
        "설명:\n",
        "- 학습용 라벨 데이터와 검증용 라벨 데이터에서 필요한 정보를 extract_info_from_survey 함수를 사용해 각각 추출하고, 이를 DataFrame으로 변환합니다.\n",
        "- train_survey_df와 valid_survey_df는 응답자 ID(R_id), 이미지 ID(image_id), 스타일 선호도(Q5)를 포함한 테이블 형태의 데이터입니다.\n",
        "\n",
        "Mission 2-2 요구 사항:\n",
        "- 학습과 검증 설문 데이터를 각각 DataFrame으로 변환하여, 응답자별 선호/비선호 데이터를 쉽게 분석할 수 있도록 준비합니다.\n",
        "\n",
        "3. 응답자 ID별 설문조사 횟수 집계 및 상위 100명 추출\n",
        "concat_survey_df = pd.concat([train_survey_df, valid_survey_df], ignore_index=True)\n",
        "R_id_count = concat_survey_df['R_id'].value_counts().head(100)\n",
        "users = R_id_count.index.tolist()\n",
        "\n",
        "설명:\n",
        "- 학습과 검증 데이터프레임을 pd.concat으로 병합하여 응답자별 설문 횟수를 집계하고, 설문 횟수가 많은 상위 100명의 응답자 ID를 추출합니다.\n",
        "- value_counts()로 응답자별 설문 횟수를 세고, head(100)으로 상위 100명의 응답자 ID를 리스트(users)에 저장합니다.\n",
        "\n",
        "Mission 2-2 요구 사항:\n",
        "응답자 중 설문조사에 가장 많이 참여한 상위 100명을 추출하여 이후의 선호/비선호 스타일 정보를 정리할 수 있도록 합니다.\n",
        "\n",
        "4. 응답자가 응답한 설문 데이터를 필터링하고 선호도 정보 추출\n",
        "data = []\n",
        "for user in users:\n",
        "    user_related_train = train_survey_df[train_survey_df['R_id'].isin([user])]\n",
        "    user_related_valid = valid_survey_df[valid_survey_df['R_id'].isin([user])]\n",
        "    info = {\n",
        "        'R_id': user,\n",
        "        'training': {\n",
        "            'like': user_related_train.loc[user_related_train['Q5'] == 2, 'image_id'].tolist(),\n",
        "            'dislike': user_related_train.loc[user_related_train['Q5'] == 1, 'image_id'].tolist()\n",
        "        },\n",
        "        'validation': {\n",
        "            'like': user_related_valid.loc[user_related_valid['Q5'] == 2, 'image_id'].tolist(),\n",
        "            'dislike': user_related_valid.loc[user_related_valid['Q5'] == 1, 'image_id'].tolist()\n",
        "        }\n",
        "    }\n",
        "    data.append(info)\n",
        "\n",
        "설명:\n",
        "- 상위 100명 응답자 각각에 대해 선호 및 비선호 이미지 목록을 정리합니다.\n",
        "user_related_train과 user_related_valid는 각 응답자가 참여한 학습 및 검증 데이터의 설문 정보입니다.\n",
        "- Q5 == 2는 선호 이미지를 나타내며, Q5 == 1은 비선호 이미지를 나타냅니다.\n",
        "like와 dislike 키에 이미지 ID를 리스트 형태로 저장하여 응답자별로 선호 및 비선호 이미지를 구분합니다.\n",
        "- 최종적으로 응답자의 ID와 그에 따른 선호/비선호 이미지 정보를 data 리스트에 저장합니다.\n",
        "\n",
        "Mission 2-2 요구 사항:\n",
        "- 각 응답자의 설문조사 데이터를 분석하여 응답자의 선호 이미지와 비선호 이미지를 분리해 정리하는 작업으로, Mission 2-2의 요구 사항을 충족합니다.\n",
        "\n",
        "5. 결과 저장\n",
        "with open('Mission2-2 Result.json', 'w') as json_file:\n",
        "    json.dump(data, json_file, indent=4)\n",
        "\n",
        "설명:\n",
        "- data 리스트를 JSON 형식으로 변환하여 Mission2-2 Result.json 파일에 저장합니다.\n",
        "- indent=4로 설정하여 JSON 파일의 가독성을 높였습니다.\n",
        "\n",
        "Mission 2-2 요구 사항:\n",
        "- 최종 결과를 JSON 파일로 저장하여 제출할 수 있는 형식을 만듭니다. 이 파일에는 응답자별 선호 및 비선호 이미지 정보가 구조화되어 저장됩니다."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ffd17b61fbf6b116"
      },
      "id": "ffd17b61fbf6b116"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Mission 2-2\n",
        "import json\n",
        "\n",
        "# 설문조사에서 미션 수행에 필요한 정보만 추출 (type = {train= 0, valid= 1})\n",
        "def extract_info_from_survey(filenames, type):\n",
        "    data = []\n",
        "    dir = \"data/training_label/\" if type==0 else \"data/validation_label/\"\n",
        "\n",
        "    for filename in filenames:\n",
        "        with open(dir+filename, 'r') as file:\n",
        "            survey_data = json.load(file)\n",
        "            extracted_data = {\n",
        "                'R_id': survey_data['user']['R_id'],\n",
        "                'image_id': survey_data['imgName'],\n",
        "                'Q5': survey_data['item']['survey']['Q5']\n",
        "            }\n",
        "            data.append(extracted_data)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# 데이터 추출\n",
        "train_survey_data = extract_info_from_survey(filtered_train_label_df['filename'], 0)\n",
        "valid_survey_data = extract_info_from_survey(filtered_valid_label_df['filename'], 1)\n",
        "\n",
        "# 추출된 데이터를 DataFrame으로 변환\n",
        "train_survey_df = pd.DataFrame(train_survey_data)\n",
        "valid_survey_df = pd.DataFrame(valid_survey_data)\n",
        "\n",
        "# 설문조사 결과가 많은 응답자 TOP 100\n",
        "concat_survey_df = pd.concat([train_survey_df, valid_survey_df], ignore_index=True)\n",
        "R_id_count = concat_survey_df['R_id'].value_counts().head(100)\n",
        "users = R_id_count.index.tolist()\n",
        "\n",
        "# 응답자가 설문에 응답한 사진 데이터만 선택 후, 선호&비선호 추출\n",
        "data = []\n",
        "for user in users:\n",
        "    user_related_train = train_survey_df[train_survey_df['R_id'].isin([user])]\n",
        "    user_related_valid = valid_survey_df[valid_survey_df['R_id'].isin([user])]\n",
        "    info = {\n",
        "        'R_id': user,\n",
        "        'training': {\n",
        "            'like': user_related_train.loc[user_related_train['Q5']==2, 'image_id'].tolist(),\n",
        "            'dislike': user_related_train.loc[user_related_train['Q5']==1, 'image_id'].tolist()\n",
        "        },\n",
        "        'validation': {\n",
        "            'like': user_related_valid.loc[user_related_valid['Q5']==2, 'image_id'].tolist(),\n",
        "            'dislike': user_related_valid.loc[user_related_valid['Q5']==1, 'image_id'].tolist()\n",
        "        }\n",
        "    }\n",
        "    data.append(info)\n",
        "\n",
        "# 결과 저장\n",
        "with open('Mission2-2 Result.json', 'w') as json_file:\n",
        "    json.dump(data, json_file, indent=4)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-30T06:32:13.938078Z",
          "start_time": "2024-10-30T06:32:11.134215Z"
        },
        "id": "d3e964fba75f8921"
      },
      "id": "d3e964fba75f8921"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "748fd0383ad8a989"
      },
      "id": "748fd0383ad8a989"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}